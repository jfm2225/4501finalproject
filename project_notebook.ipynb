{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25627e8d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
    "\n",
    "* Code clarity: make sure the code conforms to:\n",
    "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
    "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
    "    * [ ] Break each task down into logical functions\n",
    "* The following files are submitted for the project (see the project's GDoc for more details):\n",
    "    * [ ] `README.md`\n",
    "    * [ ] `requirements.txt`\n",
    "    * [ ] `.gitignore`\n",
    "    * [ ] `schema.sql`\n",
    "    * [ ] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
    "    * [x] Jupyter Notebook containing the project (this file!)\n",
    "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install geopandas\n",
    "#pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import math\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import re\n",
    "import fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b622a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any general notebook setup, like log formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need, for example:\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf38168",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Define a function that calculates the distance between two coordinates in kilometers that **only uses the `math` module** from the standard library.\n",
    "* [ ] Taxi data:\n",
    "    * [ ] Use the `re` module, and the packages `requests`, BeautifulSoup (`bs4`), and (optionally) `pandas` to programmatically download the required CSV files & load into memory.\n",
    "    * You may need to do this one file at a time - download, clean, sample. You can cache the sampling by saving it as a CSV file (and thereby freeing up memory on your computer) before moving onto the next file. \n",
    "* [ ] Weather & Uber data:\n",
    "    * [ ] Download the data manually in the link provided in the project doc.\n",
    "* [ ] All data:\n",
    "    * [ ] Load the data using `pandas`\n",
    "    * [ ] Clean the data, including:\n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * (Taxi & Uber data) Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "    * [ ] (Taxi data) Sample the data so that you have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "* [ ] Weather data:\n",
    "    * [ ] Split into two `pandas` DataFrames: one for required hourly data, and one for the required daily daya.\n",
    "    * [ ] You may find that the weather data you need later on does not exist at the frequency needed (daily vs hourly). You may calculate/generate samples from one to populate the other. Just document what you’re doing so we can follow along. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculating distance\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(df):\n",
    "# turning all coordinates into radians because all trig functions are in radians not degrees \n",
    "    lat1 = []\n",
    "    for coord in df[\"pickup_longitude\"]: \n",
    "        lat1.append(radians(coord))\n",
    "    \n",
    "    lon1 = []\n",
    "    for coord in df[\"pickup_latitude\"]: \n",
    "        lon1.append(radians(coord))\n",
    "\n",
    "    lat2 = []\n",
    "    for coord in df[\"dropoff_longitude\"]: \n",
    "        lat2.append(radians(coord))\n",
    "    \n",
    "    lon2 = []\n",
    "    for coord in df[\"dropoff_latitude\"]: \n",
    "        lon2.append(radians(coord))\n",
    "        \n",
    "    \n",
    "# calculate difference in coordinates \n",
    "    diflon = list()\n",
    "    for item1, item2 in zip(lon1, lon2): \n",
    "        diflon.append(item2 - item1)\n",
    "\n",
    "    diflat = list()\n",
    "    for item1, item2 in zip(lat1, lat2): \n",
    "        diflat.append(item2 - item1)  \n",
    "        \n",
    "        \n",
    "# calculating distance using formula \n",
    "    R = 6373.0\n",
    "    dist = list()\n",
    "    for rad1, rad2, item1, item2 in zip(diflon, diflat, lat1, lat2):\n",
    "        a = sin(rad2 / 2)**2 + cos(item1) * cos(item2) * sin(rad1 / 2)**2\n",
    "        c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "        distance = R * c \n",
    "        dist.append(distance)\n",
    "        \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_column(df):\n",
    "    df[\"distance\"] = calculate_distance(df)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac2f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(csv_file):\n",
    "    # import/read the csv file \n",
    "    UBER_DATA = pd.read_csv(csv_file) \n",
    "    \n",
    "    # dropping unnecesarry columns\n",
    "    # UBER_DATA = UBER_DATA.drop(UBER_DATA.iloc[:, 0:2],axis = 1) \n",
    "    UBER_DATA = UBER_DATA[[\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"]]\n",
    "    \n",
    "    # dropping rows where coordinates == 0\n",
    "    # create a boolean mask to check if values in rows are == 0\n",
    "    # use ~ to invert boolean mask\n",
    "    UBER_DATA = UBER_DATA[~(UBER_DATA[['pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']] == 0).any(axis=1)] \n",
    "    \n",
    "    # defining longitude and latitude bounds \n",
    "    # longitude \n",
    "    westlimit = -74.242330\n",
    "    eastlimit = -73.717047\n",
    "    # latitude \n",
    "    southlimit = 40.560445\n",
    "    northlimit = 40.908524\n",
    "    \n",
    "    # filtering out pickup data \n",
    "    pickup_longitude = UBER_DATA['pickup_longitude'].values\n",
    "    pickup_latitude = UBER_DATA['pickup_latitude'].values\n",
    "    \n",
    "        # create filters for data within longitude limits \n",
    "    pickupwest = pickup_longitude >= westlimit\n",
    "    pickupeast = pickup_longitude <= eastlimit \n",
    "    pickuplon = pickupwest * pickupeast \n",
    "    \n",
    "        # create filters for data within latitude limits \n",
    "    pickupnorth = pickup_latitude <= northlimit \n",
    "    pickupsouth = pickup_latitude >= southlimit\n",
    "    pickuplat = pickupnorth * pickupsouth \n",
    "    \n",
    "    \n",
    "        # create final pickup filter \n",
    "    \n",
    "    pickupfilter = pickuplon * pickuplat\n",
    "        \n",
    "\n",
    "    # filtering out dropoff data\n",
    "    dropoff_longitude = UBER_DATA['dropoff_longitude'].values\n",
    "    dropoff_latitude = UBER_DATA['dropoff_latitude'].values\n",
    "    \n",
    "    \n",
    "    # create filters for data within longitude limits \n",
    "    dropoffwest = dropoff_longitude >= westlimit\n",
    "    dropoffeast = dropoff_longitude <= eastlimit \n",
    "    dropofflon = dropoffwest * dropoffeast \n",
    "    \n",
    "        # create filters for data within latitude limits \n",
    "    dropoffnorth = dropoff_latitude <= northlimit \n",
    "    dropoffsouth = dropoff_latitude >= southlimit\n",
    "    dropofflat = dropoffnorth * dropoffsouth \n",
    "    \n",
    "    \n",
    "        # create final dropoff filter \n",
    "    dropofffilter = dropofflon * dropofflat\n",
    "    \n",
    "    \n",
    "    # final boundary filter\n",
    "    finalfilter = pickupfilter * dropofffilter\n",
    "    \n",
    "    # final filtered dataframe\n",
    "    UBER_DATA = UBER_DATA[finalfilter]\n",
    "    \n",
    "    \n",
    "    # normalize column datatypes \n",
    "    UBER_DATA[\"pickup_datetime\"]=pd.to_datetime(UBER_DATA[\"pickup_datetime\"])\n",
    "\n",
    "\n",
    "\n",
    "    return UBER_DATA\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_CSV)\n",
    "    add_distance_column(uber_dataframe)\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ec8dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>0.465327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>0.678941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>4.825036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>1.262035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5.371588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2012-10-28 10:49:00+00:00</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>0.064197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2014-03-14 01:09:00+00:00</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>2.442986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2009-06-29 00:42:00+00:00</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>14.269270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2015-05-20 14:56:25+00:00</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>1.800660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2010-05-15 04:08:00+00:00</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>1.500074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195472 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0      2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
       "1      2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
       "2      2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
       "3      2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
       "4      2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
       "...                          ...               ...              ...   \n",
       "199995 2012-10-28 10:49:00+00:00        -73.987042        40.739367   \n",
       "199996 2014-03-14 01:09:00+00:00        -73.984722        40.736837   \n",
       "199997 2009-06-29 00:42:00+00:00        -73.986017        40.756487   \n",
       "199998 2015-05-20 14:56:25+00:00        -73.997124        40.725452   \n",
       "199999 2010-05-15 04:08:00+00:00        -73.984395        40.720077   \n",
       "\n",
       "        dropoff_longitude  dropoff_latitude   distance  \n",
       "0              -73.999512         40.723217   0.465327  \n",
       "1              -73.994710         40.750325   0.678941  \n",
       "2              -73.962565         40.772647   4.825036  \n",
       "3              -73.965316         40.803349   1.262035  \n",
       "4              -73.973082         40.761247   5.371588  \n",
       "...                   ...               ...        ...  \n",
       "199995         -73.986525         40.740297   0.064197  \n",
       "199996         -74.006672         40.739620   2.442986  \n",
       "199997         -73.858957         40.692588  14.269270  \n",
       "199998         -73.983215         40.695415   1.800660  \n",
       "199999         -73.985508         40.768793   1.500074  \n",
       "\n",
       "[195472 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_uber_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_taxi_csv_urls():\n",
    "    response = requests.get(TAXI_URL)\n",
    "    response_page = BeautifulSoup(response.content, \"lxml\")\n",
    "    elements = response_page.find_all('a', href=True)\n",
    "\n",
    "\n",
    "    list1 = []\n",
    "    for ele in elements: \n",
    "        list1.append(ele['href'])\n",
    "    \n",
    "    links = []\n",
    "    for i in range(455): \n",
    "        string = str(list1[i])\n",
    "        pattern = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_20\\d\\d-\\d\\d.parquet\"\n",
    "        if re.search(pattern, string) is not None: \n",
    "            links.append(string)\n",
    "\n",
    "    links = links[80:]\n",
    "    \n",
    "    # putting links in chronological order \n",
    "    year15 = links[:6] # through June of 2015\n",
    "    year14 = links[12:24]\n",
    "    year13 = links[24:36]\n",
    "    year12 = links[36:48]\n",
    "    year11 = links[48:60]\n",
    "    year10 = links[60:72]\n",
    "    year09 = links[72:]\n",
    "    \n",
    "    final_links = year09 + year10 + year11 + year12 + year13 + year14 + year15\n",
    "   \n",
    "    return final_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a25487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_taxi_data(links):\n",
    "    # downloading the parquet files using the links\n",
    "    for link in links:\n",
    "        filename = link[48:]\n",
    "        response = requests.get(link)\n",
    "        open(filename,'wb').write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9f2254",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_urls = find_taxi_csv_urls()\n",
    "download_taxi_data(taxi_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "403b422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month_taxi_data1(url):\n",
    "    \n",
    "    pattern1 = \"yellow_tripdata_20\\d\\d-\\d\\d.parquet\"\n",
    "    if re.search(pattern1, url) is not None: \n",
    "        filename = re.search(pattern1, url).group()\n",
    "    \n",
    "    dataset = pd.read_parquet(filename, engine='fastparquet')\n",
    "    \n",
    "    dataset = dataset[[\"Trip_Pickup_DateTime\", \"Start_Lon\", \"Start_Lat\", \"End_Lon\", \"End_Lat\"]]\n",
    "    dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
    "    df1 = dataset\n",
    "    # dropping rows where coordinates == 0\n",
    "    # create a boolean mask to check if values in rows are == 0\n",
    "    # use ~ to invert boolean mask\n",
    "    dataset = dataset[~(dataset[['pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']] == 0).any(axis=1)] \n",
    "    \n",
    "    # defining longitude and latitude bounds \n",
    "    # longitude \n",
    "    westlimit = -74.242330\n",
    "    eastlimit = -73.717047\n",
    "    # latitude \n",
    "    southlimit = 40.560445\n",
    "    northlimit = 40.908524\n",
    "    \n",
    "    # filtering out pickup data \n",
    "    tpickup_longitude = dataset['pickup_longitude'].values\n",
    "    tpickup_latitude = dataset['pickup_latitude'].values\n",
    "    \n",
    "        # create filters for data within longitude limits \n",
    "    tpickupwest = tpickup_longitude >= westlimit\n",
    "    tpickupeast = tpickup_longitude <= eastlimit \n",
    "    tpickuplon = tpickupwest * tpickupeast \n",
    "    \n",
    "        # create filters for data within latitude limits \n",
    "    tpickupnorth = tpickup_latitude <= northlimit \n",
    "    tpickupsouth = tpickup_latitude >= southlimit\n",
    "    tpickuplat = tpickupnorth * tpickupsouth \n",
    "    \n",
    "    \n",
    "        # create final pickup filter \n",
    "    \n",
    "    tpickupfilter = tpickuplon * tpickuplat\n",
    "        \n",
    "\n",
    "    # filtering out dropoff data\n",
    "    tdropoff_longitude = dataset['dropoff_longitude'].values\n",
    "    tdropoff_latitude = dataset['dropoff_latitude'].values\n",
    "    \n",
    "        \n",
    "        # create filters for data within longitude limits \n",
    "    tdropoffwest = tdropoff_longitude >= westlimit\n",
    "    tdropoffeast = tdropoff_longitude <= eastlimit \n",
    "    tdropofflon = tdropoffwest * tdropoffeast \n",
    "    \n",
    "        # create filters for data within latitude limits \n",
    "    tdropoffnorth = tdropoff_latitude <= northlimit \n",
    "    tdropoffsouth = tdropoff_latitude >= southlimit\n",
    "    tdropofflat = tdropoffnorth * tdropoffsouth \n",
    "    \n",
    "    \n",
    "        # create final dropoff filter \n",
    "    tdropofffilter = tdropofflon * tdropofflat\n",
    "    \n",
    "    \n",
    "    # final boundary filter\n",
    "    tfinalfilter = tpickupfilter * tdropofffilter\n",
    "    \n",
    "    # final filtered dataframe\n",
    "    dataset = dataset[tfinalfilter]\n",
    "    \n",
    "    # create a random sample of data \n",
    "    # ~200,000 (size of uber sample)\n",
    "    # 84 (number of taxi datasets)\n",
    "    # ~ 2380 sampled rows per taxi dataset\n",
    "    dataset = dataset.sample(2380)\n",
    "    \n",
    "    \n",
    "    # normalize column datatypes \n",
    "    dataset[\"pickup_datetime\"]=pd.to_datetime(dataset[\"pickup_datetime\"])\n",
    "\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2824fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month_taxi_data2(url):\n",
    "    \n",
    "    pattern1 = \"yellow_tripdata_20\\d\\d-\\d\\d.parquet\"\n",
    "    if re.search(pattern1, url) is not None: \n",
    "        filename = re.search(pattern1, url).group()\n",
    "    \n",
    "    dataset = pd.read_parquet(filename, engine='fastparquet')\n",
    "    \n",
    "    dataset = dataset[[\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"]]\n",
    "    \n",
    "\n",
    "    # dropping rows where coordinates == 0\n",
    "    # create a boolean mask to check if values in rows are == 0\n",
    "    # use ~ to invert boolean mask\n",
    "    dataset = dataset[~(dataset[['pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']] == 0).any(axis=1)] \n",
    "    \n",
    "    # defining longitude and latitude bounds \n",
    "    # longitude \n",
    "    westlimit = -74.242330\n",
    "    eastlimit = -73.717047\n",
    "    # latitude \n",
    "    southlimit = 40.560445\n",
    "    northlimit = 40.908524\n",
    "    \n",
    "    # filtering out pickup data \n",
    "    tpickup_longitude = dataset['pickup_longitude'].values\n",
    "    tpickup_latitude = dataset['pickup_latitude'].values\n",
    "    \n",
    "        # create filters for data within longitude limits \n",
    "    tpickupwest = tpickup_longitude >= westlimit\n",
    "    tpickupeast = tpickup_longitude <= eastlimit \n",
    "    tpickuplon = tpickupwest * tpickupeast \n",
    "    \n",
    "        # create filters for data within latitude limits \n",
    "    tpickupnorth = tpickup_latitude <= northlimit \n",
    "    tpickupsouth = tpickup_latitude >= southlimit\n",
    "    tpickuplat = tpickupnorth * tpickupsouth \n",
    "    \n",
    "    \n",
    "        # create final pickup filter \n",
    "    \n",
    "    tpickupfilter = tpickuplon * tpickuplat\n",
    "        \n",
    "\n",
    "    # filtering out dropoff data\n",
    "    tdropoff_longitude = dataset['dropoff_longitude'].values\n",
    "    tdropoff_latitude = dataset['dropoff_latitude'].values\n",
    "    \n",
    "        \n",
    "        # create filters for data within longitude limits \n",
    "    tdropoffwest = tdropoff_longitude >= westlimit\n",
    "    tdropoffeast = tdropoff_longitude <= eastlimit \n",
    "    tdropofflon = tdropoffwest * tdropoffeast \n",
    "    \n",
    "        # create filters for data within latitude limits \n",
    "    tdropoffnorth = tdropoff_latitude <= northlimit \n",
    "    tdropoffsouth = tdropoff_latitude >= southlimit\n",
    "    tdropofflat = tdropoffnorth * tdropoffsouth \n",
    "    \n",
    "    \n",
    "        # create final dropoff filter \n",
    "    tdropofffilter = tdropofflon * tdropofflat\n",
    "    \n",
    "    \n",
    "    # final boundary filter\n",
    "    tfinalfilter = tpickupfilter * tdropofffilter\n",
    "    \n",
    "    # final filtered dataframe\n",
    "    dataset = dataset[tfinalfilter]\n",
    "    \n",
    "    # create a random sample of data \n",
    "    # ~200,000 (size of uber sample)\n",
    "    # 84 (number of taxi datasets)\n",
    "    # ~ 2380 sampled rows per taxi dataset\n",
    "    dataset = dataset.sample(2380)\n",
    "    \n",
    "    \n",
    "    # normalize column datatypes \n",
    "    dataset[\"pickup_datetime\"]=pd.to_datetime(dataset[\"pickup_datetime\"])\n",
    "\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed18b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month_taxi_data3(url):\n",
    "    \n",
    "    shapefile = gpd.read_file(\"taxi_zones.shp\")\n",
    "    shapefile = shapefile[[\"LocationID\",\"geometry\"]]\n",
    "    shapefile = shapefile.to_crs(epsg = 4326)\n",
    "    shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
    "    shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
    "    shapefile.index = np.arange(1,264)\n",
    "    shapefile = shapefile[['lon','lat']]\n",
    "    longitude = shapefile['lon']\n",
    "    latitude = shapefile['lat']\n",
    "    \n",
    "    pattern = \"yellow_tripdata_20\\d\\d-\\d\\d.parquet\"\n",
    "    if re.search(pattern, url) is not None: \n",
    "        filename = re.search(pattern, url).group()\n",
    "    \n",
    "    dataset = pd.read_parquet(filename, engine='fastparquet')\n",
    "    dataset = dataset[[\"tpep_pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"trip_distance\"]]\n",
    "    dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
    "    \n",
    "    pulocationidfilter = dataset['PULocationID'] <= 263\n",
    "    dolocationidfilter = dataset['DOLocationID'] <= 263\n",
    "    validityfilter = pulocationidfilter & dolocationidfilter\n",
    "    \n",
    "    dataset = dataset[validityfilter] # gets rid  of nonvalid IDs \n",
    "\n",
    "    pulon = []\n",
    "    pulat = []\n",
    "    for idpu in dataset['PULocationID']: \n",
    "        pulon.append(longitude[idpu])\n",
    "        pulat.append(latitude[idpu])\n",
    "        \n",
    "    dataset['pickup_longitude'] = pulon\n",
    "    dataset['pickup_latitude'] = pulat\n",
    "        \n",
    "    dolon = []\n",
    "    dolat = []\n",
    "    for iddo in dataset['DOLocationID']: \n",
    "        dolon.append(longitude[iddo])\n",
    "        dolat.append(latitude[iddo])\n",
    "        \n",
    "    dataset['dropoff_longitude'] = dolon\n",
    "    dataset['dropoff_latitude'] = dolat\n",
    "    \n",
    "    dataset = dataset[[\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"]]\n",
    "    \n",
    "        # dropping rows where coordinates == 0\n",
    "    # create a boolean mask to check if values in rows are == 0\n",
    "    # use ~ to invert boolean mask\n",
    "    dataset = dataset[~(dataset[['pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']] == 0).any(axis=1)] \n",
    "    \n",
    "    # defining longitude and latitude bounds \n",
    "    # longitude \n",
    "    westlimit = -74.242330\n",
    "    eastlimit = -73.717047\n",
    "    # latitude \n",
    "    southlimit = 40.560445\n",
    "    northlimit = 40.908524\n",
    "    \n",
    "    # filtering out pickup data \n",
    "    tpickup_longitude = dataset['pickup_longitude'].values\n",
    "    tpickup_latitude = dataset['pickup_latitude'].values\n",
    "    \n",
    "        # create filters for data within longitude limits \n",
    "    tpickupwest = tpickup_longitude >= westlimit\n",
    "    tpickupeast = tpickup_longitude <= eastlimit \n",
    "    tpickuplon = tpickupwest * tpickupeast \n",
    "    \n",
    "        # create filters for data within latitude limits \n",
    "    tpickupnorth = tpickup_latitude <= northlimit \n",
    "    tpickupsouth = tpickup_latitude >= southlimit\n",
    "    tpickuplat = tpickupnorth * tpickupsouth \n",
    "    \n",
    "    \n",
    "        # create final pickup filter \n",
    "    \n",
    "    tpickupfilter = tpickuplon * tpickuplat\n",
    "        \n",
    "\n",
    "    # filtering out dropoff data\n",
    "    tdropoff_longitude = dataset['dropoff_longitude'].values\n",
    "    tdropoff_latitude = dataset['dropoff_latitude'].values\n",
    "    \n",
    "        \n",
    "        # create filters for data within longitude limits \n",
    "    tdropoffwest = tdropoff_longitude >= westlimit\n",
    "    tdropoffeast = tdropoff_longitude <= eastlimit \n",
    "    tdropofflon = tdropoffwest * tdropoffeast \n",
    "    \n",
    "        # create filters for data within latitude limits \n",
    "    tdropoffnorth = tdropoff_latitude <= northlimit \n",
    "    tdropoffsouth = tdropoff_latitude >= southlimit\n",
    "    tdropofflat = tdropoffnorth * tdropoffsouth \n",
    "    \n",
    "    \n",
    "        # create final dropoff filter \n",
    "    tdropofffilter = tdropofflon * tdropofflat\n",
    "    \n",
    "    \n",
    "    # final boundary filter\n",
    "    tfinalfilter = tpickupfilter * tdropofffilter\n",
    "    \n",
    "    # final filtered dataframe\n",
    "    dataset = dataset[tfinalfilter]\n",
    "    \n",
    "    # create a random sample of data \n",
    "    # ~200,000 (size of uber sample)\n",
    "    # 84 (number of taxi datasets)\n",
    "    # ~ 2380 sampled rows per taxi dataset\n",
    "    dataset = dataset.sample(2380)\n",
    "    \n",
    "    \n",
    "    # normalize column datatypes \n",
    "    dataset[\"pickup_datetime\"]=pd.to_datetime(dataset[\"pickup_datetime\"])\n",
    "              \n",
    "    return dataset\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data():\n",
    "    \n",
    "    all_taxi_dataframes = []\n",
    "    taxi_urls = find_taxi_csv_urls()\n",
    "    csv_urls1 = taxi_urls[:12]\n",
    "    csv_urls2 = taxi_urls[12:24]\n",
    "    csv_urls3 = taxi_urls[24:]\n",
    "\n",
    "    \n",
    "    for csv_url in csv_urls1:\n",
    "        dataframe1 = get_and_clean_month_taxi_data1(csv_url)\n",
    "        add_distance_column(dataframe1)\n",
    "        all_taxi_dataframes.append(dataframe1)\n",
    "    \n",
    "    for csv_url in csv_urls2:\n",
    "        dataframe2 = get_and_clean_month_taxi_data2(csv_url)\n",
    "        add_distance_column(dataframe2)\n",
    "        all_taxi_dataframes.append(dataframe2)\n",
    "        \n",
    "        \n",
    "    for csv_url in csv_urls3:\n",
    "        dataframe3 = get_and_clean_month_taxi_data3(csv_url)\n",
    "        add_distance_column(dataframe3)\n",
    "        all_taxi_dataframes.append(dataframe3)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    #taxi_data = pd.concact(all_taxi_dataframes)\n",
    "    \n",
    "    \n",
    "    taxi_data = []\n",
    "    for dataframe in all_taxi_dataframes: \n",
    "        taxi_data.append(dataframe)\n",
    "        \n",
    "                            \n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f80f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_urls = find_taxi_csv_urls()\n",
    "#get_and_clean_month_taxi_data1(taxi_urls[11])\n",
    "#get_and_clean_month_taxi_data2(taxi_urls[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c311ed",
   "metadata": {},
   "source": [
    "def test(url): \n",
    "    pattern = \"yellow_tripdata_20\\d\\d-\\d\\d.parquet\"\n",
    "    if re.search(pattern, url) is not None: \n",
    "        filename = re.search(pattern, url).group()\n",
    "    \n",
    "    dataset = pd.read_parquet(filename, engine='fastparquet')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7565cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taxi_data = get_and_clean_taxi_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "_In this section, the processesing of data before performing analyses continues. The data is split into two different dataframes so that alayses can be run at different frequencies. NaN and invalid data points are dropped as part of cleaning the data. Regex is also used to extract just didgits from the dataframe. _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    \n",
    "    # import/read csv file \n",
    "    data = pd.read_csv(csv_file, low_memory = False) \n",
    "    # drop NAN values for precipitation\n",
    "    cleaned_data = data.dropna(axis=0, subset = \"HourlyPrecipitation\") \n",
    "    # dropping rows where precipitation == T (trace amounts)\n",
    "    # create a boolean mask to check if values in rows are == T\n",
    "    # use ~ to invert boolean mask\n",
    "    cleaned_data = cleaned_data[~(cleaned_data[\"HourlyPrecipitation\"] == 'T')]\n",
    "    # only extract digits from column \n",
    "    cleaned_data[\"HourlyPrecipitation\"] = cleaned_data[\"HourlyPrecipitation\"].replace('\\(|[a-zA-Z]+', '', regex=True)\n",
    "    # drop NAN values for wind speed\n",
    "    cleaned_data = cleaned_data.dropna(axis=0, subset = \"HourlyWindSpeed\") \n",
    "    # create a dataframe with only the necessary columns \n",
    "    cleaned_data = cleaned_data[[\"DATE\",\"HourlyPrecipitation\",\"HourlyWindSpeed\"]]\n",
    "    # standardize datatypes\n",
    "    cleaned_data[\"DATE\"] = pd.to_datetime(cleaned_data[\"DATE\"])\n",
    "    cleaned_data[\"HourlyPrecipitation\"] = pd.to_numeric(cleaned_data[\"HourlyPrecipitation\"])\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    # load cleaned hourly data\n", 
    "    cleaned_hourly = clean_month_weather_data_hourly(csv_file)\n",
    "    # groupby each day and assign the average of the hourly values to a daily value\n",
    "    daily = cleaned_hourly.groupby([cleaned_hourly['DATE'].dt.date]).mean()\n",
    "    \n",
    "    return daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "    \n",
    "    # add the name/paths manually\n",
    "    weather_csv_files = [\"2009_weather.csv\", \"2010_weather.csv\",\"2011_weather.csv\",\"2012_weather.csv\",\"2013_weather.csv\",\"2014_weather.csv\",\"2015_weather.csv\" ]\n",
    "    \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "    # create two dataframes with hourly & daily data from every month (YEAR?)\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900f7aa",
   "metadata": {},
   "source": [
    "### Process All Data\n",
    "\n",
    "_This is where you can actually execute all the required functions._\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\705598918.py:10: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\705598918.py:10: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\705598918.py:10: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\705598918.py:10: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\705598918.py:10: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\705598918.py:10: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\705598918.py:10: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\705598918.py:10: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\705598918.py:10: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\705598918.py:10: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\705598918.py:10: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\705598918.py:10: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lon\"] = shapefile.geometry.centroid.x\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shapefile[\"lat\"] = shapefile.geometry.centroid.y\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\203980312.py:19: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  dataset = dataset.set_axis([\"pickup_datetime\", \"PULocationID\", \"DOLocationID\", \"distance\"], axis=1, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "taxi_data = get_and_clean_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7c29c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6891767</th>\n",
       "      <td>2009-01-08 22:35:00</td>\n",
       "      <td>-73.981912</td>\n",
       "      <td>40.773760</td>\n",
       "      <td>-73.932862</td>\n",
       "      <td>40.797493</td>\n",
       "      <td>5.504381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14030472</th>\n",
       "      <td>2009-01-16 10:22:30</td>\n",
       "      <td>-73.955361</td>\n",
       "      <td>40.768600</td>\n",
       "      <td>-73.953716</td>\n",
       "      <td>40.764845</td>\n",
       "      <td>0.216348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10841276</th>\n",
       "      <td>2009-01-19 17:00:00</td>\n",
       "      <td>-73.953937</td>\n",
       "      <td>40.766288</td>\n",
       "      <td>-73.970498</td>\n",
       "      <td>40.788372</td>\n",
       "      <td>1.963107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10888292</th>\n",
       "      <td>2009-01-22 23:34:00</td>\n",
       "      <td>-74.000023</td>\n",
       "      <td>40.732717</td>\n",
       "      <td>-73.986537</td>\n",
       "      <td>40.732678</td>\n",
       "      <td>1.500046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420072</th>\n",
       "      <td>2009-01-31 13:32:00</td>\n",
       "      <td>-73.966833</td>\n",
       "      <td>40.788605</td>\n",
       "      <td>-73.967702</td>\n",
       "      <td>40.761842</td>\n",
       "      <td>0.827826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9038939</th>\n",
       "      <td>2015-06-22 19:13:16</td>\n",
       "      <td>-73.978492</td>\n",
       "      <td>40.747746</td>\n",
       "      <td>-73.965635</td>\n",
       "      <td>40.768615</td>\n",
       "      <td>1.567144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179167</th>\n",
       "      <td>2015-06-01 13:11:57</td>\n",
       "      <td>-73.976495</td>\n",
       "      <td>40.740439</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>0.847901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894518</th>\n",
       "      <td>2015-06-07 18:49:26</td>\n",
       "      <td>-73.990458</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.981414</td>\n",
       "      <td>40.670374</td>\n",
       "      <td>2.370846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11367055</th>\n",
       "      <td>2015-06-28 10:34:30</td>\n",
       "      <td>-73.965635</td>\n",
       "      <td>40.768615</td>\n",
       "      <td>-73.951010</td>\n",
       "      <td>40.778766</td>\n",
       "      <td>1.656349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11954257</th>\n",
       "      <td>2015-06-30 00:51:53</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>-73.992438</td>\n",
       "      <td>40.748497</td>\n",
       "      <td>0.999104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185640 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "6891767  2009-01-08 22:35:00        -73.981912        40.773760   \n",
       "14030472 2009-01-16 10:22:30        -73.955361        40.768600   \n",
       "10841276 2009-01-19 17:00:00        -73.953937        40.766288   \n",
       "10888292 2009-01-22 23:34:00        -74.000023        40.732717   \n",
       "3420072  2009-01-31 13:32:00        -73.966833        40.788605   \n",
       "...                      ...               ...              ...   \n",
       "9038939  2015-06-22 19:13:16        -73.978492        40.747746   \n",
       "179167   2015-06-01 13:11:57        -73.976495        40.740439   \n",
       "2894518  2015-06-07 18:49:26        -73.990458        40.740337   \n",
       "11367055 2015-06-28 10:34:30        -73.965635        40.768615   \n",
       "11954257 2015-06-30 00:51:53        -73.984052        40.736824   \n",
       "\n",
       "          dropoff_longitude  dropoff_latitude  distance  \n",
       "6891767          -73.932862         40.797493  5.504381  \n",
       "14030472         -73.953716         40.764845  0.216348  \n",
       "10841276         -73.970498         40.788372  1.963107  \n",
       "10888292         -73.986537         40.732678  1.500046  \n",
       "3420072          -73.967702         40.761842  0.827826  \n",
       "...                     ...               ...       ...  \n",
       "9038939          -73.965635         40.768615  1.567144  \n",
       "179167           -73.984052         40.736824  0.847901  \n",
       "2894518          -73.981414         40.670374  2.370846  \n",
       "11367055         -73.951010         40.778766  1.656349  \n",
       "11954257         -73.992438         40.748497  0.999104  \n",
       "\n",
       "[185640 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data = pd.concat(taxi_data)\n",
    "taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61b49fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>0.465327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>0.678941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>4.825036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>1.262035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5.371588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2012-10-28 10:49:00+00:00</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>0.064197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2014-03-14 01:09:00+00:00</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>2.442986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2009-06-29 00:42:00+00:00</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>14.269270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2015-05-20 14:56:25+00:00</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>1.800660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2010-05-15 04:08:00+00:00</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>1.500074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195472 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0      2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
       "1      2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
       "2      2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
       "3      2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
       "4      2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
       "...                          ...               ...              ...   \n",
       "199995 2012-10-28 10:49:00+00:00        -73.987042        40.739367   \n",
       "199996 2014-03-14 01:09:00+00:00        -73.984722        40.736837   \n",
       "199997 2009-06-29 00:42:00+00:00        -73.986017        40.756487   \n",
       "199998 2015-05-20 14:56:25+00:00        -73.997124        40.725452   \n",
       "199999 2010-05-15 04:08:00+00:00        -73.984395        40.720077   \n",
       "\n",
       "        dropoff_longitude  dropoff_latitude   distance  \n",
       "0              -73.999512         40.723217   0.465327  \n",
       "1              -73.994710         40.750325   0.678941  \n",
       "2              -73.962565         40.772647   4.825036  \n",
       "3              -73.965316         40.803349   1.262035  \n",
       "4              -73.973082         40.761247   5.371588  \n",
       "...                   ...               ...        ...  \n",
       "199995         -73.986525         40.740297   0.064197  \n",
       "199996         -74.006672         40.739620   2.442986  \n",
       "199997         -73.858957         40.692588  14.269270  \n",
       "199998         -73.983215         40.695415   1.800660  \n",
       "199999         -73.985508         40.768793   1.500074  \n",
       "\n",
       "[195472 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data = get_uber_data()\n",
    "uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a502ce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\1294668373.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  daily = cleaned_hourly.groupby([cleaned_hourly['DATE'].dt.date]).mean()\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\1294668373.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  daily = cleaned_hourly.groupby([cleaned_hourly['DATE'].dt.date]).mean()\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\1294668373.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  daily = cleaned_hourly.groupby([cleaned_hourly['DATE'].dt.date]).mean()\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\1294668373.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  daily = cleaned_hourly.groupby([cleaned_hourly['DATE'].dt.date]).mean()\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\1294668373.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  daily = cleaned_hourly.groupby([cleaned_hourly['DATE'].dt.date]).mean()\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\1294668373.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  daily = cleaned_hourly.groupby([cleaned_hourly['DATE'].dt.date]).mean()\n",
      "C:\\Users\\johnf\\AppData\\Local\\Temp\\ipykernel_20196\\1294668373.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  daily = cleaned_hourly.groupby([cleaned_hourly['DATE'].dt.date]).mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "      <th>DailyWindSpeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-06</th>\n",
       "      <td>0.017143</td>\n",
       "      <td>8.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-07</th>\n",
       "      <td>0.058710</td>\n",
       "      <td>10.387097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-10</th>\n",
       "      <td>0.020500</td>\n",
       "      <td>9.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-11</th>\n",
       "      <td>0.039231</td>\n",
       "      <td>8.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-15</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-27</th>\n",
       "      <td>0.007391</td>\n",
       "      <td>5.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-28</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>8.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-29</th>\n",
       "      <td>0.028182</td>\n",
       "      <td>7.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30</th>\n",
       "      <td>0.011154</td>\n",
       "      <td>4.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>0.003333</td>\n",
       "      <td>5.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1664 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DailyPrecipitation  DailyWindSpeed\n",
       "DATE                                          \n",
       "2009-01-06            0.017143        8.857143\n",
       "2009-01-07            0.058710       10.387097\n",
       "2009-01-10            0.020500        9.250000\n",
       "2009-01-11            0.039231        8.769231\n",
       "2009-01-15            0.010000        7.000000\n",
       "...                        ...             ...\n",
       "2015-12-27            0.007391        5.521739\n",
       "2015-12-28            0.001500        8.150000\n",
       "2015-12-29            0.028182        7.303030\n",
       "2015-12-30            0.011154        4.115385\n",
       "2015-12-31            0.003333        5.375000\n",
       "\n",
       "[1664 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()\n",
    "daily_weather_data = daily_weather_data.rename(columns={'HourlyPrecipitation':'DailyPrecipitation',\n",
    "                                  'HourlyWindSpeed':'DailyWindSpeed'})\n",
    "daily_weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data\n",
    "\n",
    "While the dataframes we have stored our data in are convenient for coding purposes, they are impermanent and take a long time to process, so we would like to store them so that we do not have to generate them every time. We do this by writing them into SQL tables in a database we define. We will name our database \"project.db\" and write our dataframes into it by using Pandas' .to_sql functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine('sqlite:///project.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a776b4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185640"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data.to_sql('hourlyWeather',con=engine, if_exists='replace',index_label='id')\n",
    "daily_weather_data.to_sql('dailyWeather',con=engine, if_exists='replace',index_label='id')\n",
    "uber_data.to_sql('uber',con=engine, if_exists='replace',index_label='id')\n",
    "taxi_data.to_sql('taxi',con=engine, if_exists='replace',index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data\n",
    "\n",
    "In this section, we will run several queries on the data we have stored in SQL tables. We do this to get a better understanding of the shape and scope of our data. For each query, we have a particular question in mind that we will answer by calling relevant data. At times, we may summarize the data by counting rows or taking averages. In the next cell, we define a function that will write the prose of our queries into .sql files so that we can call them later without having to write them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_to_file(query, outfile):\n",
    "    \"\"\"Write a given SQL query string to a file called outfile.\"\"\"\n",
    "    f = open(outfile,'w')\n",
    "    f.write(query)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1\n",
    "\n",
    "Here we will find what hour of the day was the most popular to take a Yellow Taxi by counting the number of rows in our table corresponding to each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1 = \"\"\"\n",
    "SELECT \n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%00:%' THEN 1 END) AS '00',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%01:%' THEN 1 END) AS '01',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%02:%' THEN 1 END) AS '02',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%03:%' THEN 1 END) AS '03',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%04:%' THEN 1 END) AS '04',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%05:%' THEN 1 END) AS '05',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%06:%' THEN 1 END) AS '06',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%07:%' THEN 1 END) AS '07',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%08:%' THEN 1 END) AS '08',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%09:%' THEN 1 END) AS '09',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%10:%' THEN 1 END) AS '10',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%11:%' THEN 1 END) AS '11',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%12:%' THEN 1 END) AS '12',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%13:%' THEN 1 END) AS '13',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%14:%' THEN 1 END) AS '14',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%15:%' THEN 1 END) AS '15',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%16:%' THEN 1 END) AS '16',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%17:%' THEN 1 END) AS '17',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%18:%' THEN 1 END) AS '18',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%19:%' THEN 1 END) AS '19',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%20:%' THEN 1 END) AS '20',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%21:%' THEN 1 END) AS '21',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%22:%' THEN 1 END) AS '22',\n",
    "COUNT(CASE WHEN pickup_datetime LIKE '%23:%' THEN 1 END) AS '23'\n",
    "FROM taxi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10198, 8420, 7064, 5899, 5128, 4950, 6710, 9844, 11445, 11797, 11223, 11812, 12021, 12016, 12171, 11885, 10501, 12413, 13956, 14770, 13902, 13585, 13149, 11934)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_1).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, \"popular_taxi_hours.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e78ad",
   "metadata": {},
   "source": [
    "### Query 2\n",
    "\n",
    "Here we will find what day was the most popular to take an Uber by counting the number of rows in our table corresponding to each day of the week.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "400124c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2 = \"\"\"\n",
    "SELECT\n",
    "COUNT(CASE WHEN strftime('%w',pickup_datetime) IS '0' THEN 1 END) AS 'Sunday',\n",
    "COUNT(CASE WHEN strftime('%w',pickup_datetime) IS '1' THEN 1 END) AS 'Monday',\n",
    "COUNT(CASE WHEN strftime('%w',pickup_datetime) IS '2' THEN 1 END) AS 'Tuesday',\n",
    "COUNT(CASE WHEN strftime('%w',pickup_datetime) IS '3' THEN 1 END) AS 'Wednesday',\n",
    "COUNT(CASE WHEN strftime('%w',pickup_datetime) IS '4' THEN 1 END) AS 'Thursday',\n",
    "COUNT(CASE WHEN strftime('%w',pickup_datetime) IS '5' THEN 1 END) AS 'Friday',\n",
    "COUNT(CASE WHEN strftime('%w',pickup_datetime) IS '6' THEN 1 END) AS 'Saturday'\n",
    "FROM uber\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25bdf691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25834, 24681, 27526, 28328, 29338, 30166, 29599)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_2).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c415563",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_2, \"popular_uber_days.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b09401",
   "metadata": {},
   "source": [
    "### Query 3\n",
    "\n",
    "Here we will find the 95% percentile of distance traveled for all hired trips during July 2013 by forming a union between our Yellow Taxi data and Uber data and finding what distance encompasses 95% of all rides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e3b0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3 = \"\"\"\n",
    "SELECT distance\n",
    "FROM taxi\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT distance\n",
    "FROM uber\n",
    "ORDER BY distance DESC\n",
    "LIMIT 1 OFFSET 19055\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0321c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10.438645448958848,)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_3).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82810039",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_3, \"rides_95th_percentile.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd0dd5",
   "metadata": {},
   "source": [
    "### Query 4\n",
    "\n",
    "Here we find the 10 days with the most hired rides and their average distance by filtering our union and grouping by day. We then order by number of rides per day and select the top 10 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9db09a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4 = \"\"\"\n",
    "SELECT pickup_datetime, AVG(distance)\n",
    "FROM (\n",
    "SELECT *\n",
    "FROM taxi\n",
    "WHERE pickup_datetime LIKE '2009%'\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT *\n",
    "FROM uber\n",
    "WHERE pickup_datetime LIKE '2009%'\n",
    ")\n",
    "GROUP BY pickup_datetime\n",
    "ORDER BY COUNT(pickup_datetime) DESC\n",
    "LIMIT 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecb0a5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2009-08-21 19:01:00.000000', 2.3004645356549798),\n",
       " ('2009-02-12 12:46:00.000000', 2.06106123864422),\n",
       " ('2009-12-29 19:49:00.000000', 1.359449274955546),\n",
       " ('2009-12-22 11:08:00.000000', 1.0413531499025293),\n",
       " ('2009-12-16 13:05:00.000000', 2.591184118342559),\n",
       " ('2009-12-06 18:24:00.000000', 3.0824503260395963),\n",
       " ('2009-12-01 15:03:00.000000', 2.170797180883661),\n",
       " ('2009-11-23 17:51:00.000000', 2.4266183086888327),\n",
       " ('2009-11-14 00:41:00.000000', 7.162453247895702),\n",
       " ('2009-11-05 23:39:00.000000', 3.015314787749366)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_4).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29582a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_4, \"avg_dist_of_busiest_days_2009.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbabec66",
   "metadata": {},
   "source": [
    "### Query 5\n",
    "\n",
    "Here we will find what days in 2014 were the windiest and how many rides were taken on those days by grouping our rides by the day, joining with our daily weather reports, and ordering by windiest days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2440113",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5 = \"\"\"\n",
    "SELECT strftime('%Y-%m-%d',pickup_datetime) AS date, COUNT(\n",
    "    (SELECT distance FROM taxi WHERE pickup_datetime LIKE '2014%'\n",
    "    UNION ALL\n",
    "    SELECT distance FROM uber WHERE pickup_datetime LIKE '2014%'\n",
    "    ) \n",
    "    )\n",
    "FROM (\n",
    "SELECT *\n",
    "FROM taxi\n",
    "WHERE pickup_datetime LIKE '2014%'\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT *\n",
    "FROM uber\n",
    "WHERE pickup_datetime LIKE '2014%'\n",
    ") AS a\n",
    "\n",
    "JOIN dailyWeather ON strftime('%Y-%m-%d',a.pickup_datetime)=dailyWeather.id\n",
    "GROUP BY strftime('%Y-%m-%d',pickup_datetime)\n",
    "ORDER BY dailyWeather.DailyWindSpeed DESC\n",
    "LIMIT 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47462cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2014-03-13', 197),\n",
       " ('2014-01-07', 162),\n",
       " ('2014-01-02', 125),\n",
       " ('2014-02-13', 119),\n",
       " ('2014-03-26', 170),\n",
       " ('2014-03-29', 199),\n",
       " ('2014-12-07', 156),\n",
       " ('2014-12-09', 153),\n",
       " ('2014-12-08', 154),\n",
       " ('2014-11-02', 147)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_5).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ec478f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_5, \"windy_days_with_trips.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292c72bf",
   "metadata": {},
   "source": [
    "### Query 6\n",
    "\n",
    "Here we will find the number of rides taken, precipitation and wind speed for every hour in the two week period surrounding Hurricane Sandy's presence in NYC. We group our rides by hour and limit our search to the desired time period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2fb04f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6 = \"\"\"\n",
    "SELECT COUNT(\n",
    "    (SELECT distance FROM taxi WHERE (\n",
    "       pickup_datetime LIKE '2012-10-22%'\n",
    "    OR pickup_datetime LIKE '2012-10-23%'\n",
    "    OR pickup_datetime LIKE '2012-10-24%'\n",
    "    OR pickup_datetime LIKE '2012-10-25%'\n",
    "    OR pickup_datetime LIKE '2012-10-26%'\n",
    "    OR pickup_datetime LIKE '2012-10-27%'\n",
    "    OR pickup_datetime LIKE '2012-10-28%'\n",
    "    OR pickup_datetime LIKE '2012-10-29%'\n",
    "    OR pickup_datetime LIKE '2012-10-30%'\n",
    "    OR pickup_datetime LIKE '2012-10-31%'\n",
    "    OR pickup_datetime LIKE '2012-11-01%'\n",
    "    OR pickup_datetime LIKE '2012-11-02%'\n",
    "    OR pickup_datetime LIKE '2012-11-03%'\n",
    "    OR pickup_datetime LIKE '2012-11-04%'\n",
    "    OR pickup_datetime LIKE '2012-11-05%'\n",
    "    OR pickup_datetime LIKE '2012-11-06%'\n",
    "    )\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT distance FROM uber WHERE (\n",
    "       pickup_datetime LIKE '2012-10-22%'\n",
    "    OR pickup_datetime LIKE '2012-10-23%'\n",
    "    OR pickup_datetime LIKE '2012-10-24%'\n",
    "    OR pickup_datetime LIKE '2012-10-25%'\n",
    "    OR pickup_datetime LIKE '2012-10-26%'\n",
    "    OR pickup_datetime LIKE '2012-10-27%'\n",
    "    OR pickup_datetime LIKE '2012-10-28%'\n",
    "    OR pickup_datetime LIKE '2012-10-29%'\n",
    "    OR pickup_datetime LIKE '2012-10-30%'\n",
    "    OR pickup_datetime LIKE '2012-10-31%'\n",
    "    OR pickup_datetime LIKE '2012-11-01%'\n",
    "    OR pickup_datetime LIKE '2012-11-02%'\n",
    "    OR pickup_datetime LIKE '2012-11-03%'\n",
    "    OR pickup_datetime LIKE '2012-11-04%'\n",
    "    OR pickup_datetime LIKE '2012-11-05%'\n",
    "    OR pickup_datetime LIKE '2012-11-06%'\n",
    "    ) \n",
    "    )), hourlyWeather.HourlyPrecipitation, hourlyWeather.HourlyWindSpeed\n",
    "FROM (\n",
    "    SELECT * FROM taxi WHERE (\n",
    "       pickup_datetime LIKE '2012-10-22%'\n",
    "    OR pickup_datetime LIKE '2012-10-23%'\n",
    "    OR pickup_datetime LIKE '2012-10-24%'\n",
    "    OR pickup_datetime LIKE '2012-10-25%'\n",
    "    OR pickup_datetime LIKE '2012-10-26%'\n",
    "    OR pickup_datetime LIKE '2012-10-27%'\n",
    "    OR pickup_datetime LIKE '2012-10-28%'\n",
    "    OR pickup_datetime LIKE '2012-10-29%'\n",
    "    OR pickup_datetime LIKE '2012-10-30%'\n",
    "    OR pickup_datetime LIKE '2012-10-31%'\n",
    "    OR pickup_datetime LIKE '2012-11-01%'\n",
    "    OR pickup_datetime LIKE '2012-11-02%'\n",
    "    OR pickup_datetime LIKE '2012-11-03%'\n",
    "    OR pickup_datetime LIKE '2012-11-04%'\n",
    "    OR pickup_datetime LIKE '2012-11-05%'\n",
    "    OR pickup_datetime LIKE '2012-11-06%'\n",
    "    )\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT * FROM uber WHERE (\n",
    "       pickup_datetime LIKE '2012-10-22%'\n",
    "    OR pickup_datetime LIKE '2012-10-23%'\n",
    "    OR pickup_datetime LIKE '2012-10-24%'\n",
    "    OR pickup_datetime LIKE '2012-10-25%'\n",
    "    OR pickup_datetime LIKE '2012-10-26%'\n",
    "    OR pickup_datetime LIKE '2012-10-27%'\n",
    "    OR pickup_datetime LIKE '2012-10-28%'\n",
    "    OR pickup_datetime LIKE '2012-10-29%'\n",
    "    OR pickup_datetime LIKE '2012-10-30%'\n",
    "    OR pickup_datetime LIKE '2012-10-31%'\n",
    "    OR pickup_datetime LIKE '2012-11-01%'\n",
    "    OR pickup_datetime LIKE '2012-11-02%'\n",
    "    OR pickup_datetime LIKE '2012-11-03%'\n",
    "    OR pickup_datetime LIKE '2012-11-04%'\n",
    "    OR pickup_datetime LIKE '2012-11-05%'\n",
    "    OR pickup_datetime LIKE '2012-11-06%'\n",
    "    )\n",
    ") AS a\n",
    "JOIN hourlyWeather ON strftime('%Y-%m-%d %H',a.pickup_datetime)=strftime('%Y-%m-%d %H',hourlyWeather.date)\n",
    "GROUP BY strftime('%Y-%m-%d %H',a.pickup_datetime)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "756c37ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.0, 7.0),\n",
       " (2, 0.0, 5.0),\n",
       " (2, 0.0, 7.0),\n",
       " (1, 0.0, 0.0),\n",
       " (1, 0.0, 0.0),\n",
       " (6, 0.0, 5.0),\n",
       " (10, 0.0, 3.0),\n",
       " (8, 0.0, 3.0),\n",
       " (9, 0.0, 5.0),\n",
       " (8, 0.0, 11.0),\n",
       " (7, 0.0, 7.0),\n",
       " (7, 0.0, 6.0),\n",
       " (8, 0.0, 3.0),\n",
       " (8, 0.0, 7.0),\n",
       " (15, 0.0, 5.0),\n",
       " (4, 0.0, 5.0),\n",
       " (11, 0.0, 3.0),\n",
       " (5, 0.0, 0.0),\n",
       " (10, 0.0, 3.0),\n",
       " (5, 0.0, 3.0),\n",
       " (12, 0.02, 0.0),\n",
       " (11, 0.01, 0.0),\n",
       " (2, 0.0, 3.0),\n",
       " (1, 0.0, 5.0),\n",
       " (4, 0.0, 5.0),\n",
       " (1, 0.0, 7.0),\n",
       " (1, 0.0, 7.0),\n",
       " (5, 0.0, 6.0),\n",
       " (1, 0.0, 3.0),\n",
       " (4, 0.0, 7.0),\n",
       " (9, 0.0, 7.0),\n",
       " (7, 0.0, 8.0),\n",
       " (3, 0.0, 7.0),\n",
       " (9, 0.0, 7.0),\n",
       " (5, 0.0, 8.0),\n",
       " (8, 0.0, 5.0),\n",
       " (6, 0.0, 7.0),\n",
       " (14, 0.0, 8.0),\n",
       " (17, 0.0, 3.0),\n",
       " (12, 0.0, 5.0),\n",
       " (7, 0.0, 6.0),\n",
       " (9, 0.0, 0.0),\n",
       " (8, 0.0, 3.0),\n",
       " (3, 0.0, 3.0),\n",
       " (2, 0.0, 3.0),\n",
       " (1, 0.0, 6.0),\n",
       " (3, 0.0, 0.0),\n",
       " (7, 0.0, 5.0),\n",
       " (9, 0.0, 6.0),\n",
       " (9, 0.0, 5.0),\n",
       " (7, 0.0, 3.0),\n",
       " (9, 0.0, 6.0),\n",
       " (13, 0.0, 0.0),\n",
       " (10, 0.0, 6.0),\n",
       " (10, 0.0, 0.0),\n",
       " (11, 0.0, 5.0),\n",
       " (7, 0.0, 5.0),\n",
       " (4, 0.0, 0.0),\n",
       " (8, 0.0, 3.0),\n",
       " (12, 0.0, 0.0),\n",
       " (4, 0.0, 0.0),\n",
       " (14, 0.0, 3.0),\n",
       " (14, 0.0, 3.0),\n",
       " (14, 0.0, 3.0),\n",
       " (14, 0.0, 0.0),\n",
       " (8, 0.0, 5.0),\n",
       " (8, 0.0, 0.0),\n",
       " (3, 0.0, 0.0),\n",
       " (3, 0.0, 3.0),\n",
       " (5, 0.0, 0.0),\n",
       " (1, 0.0, 0.0),\n",
       " (3, 0.0, 0.0),\n",
       " (9, 0.0, 3.0),\n",
       " (5, 0.0, 3.0),\n",
       " (9, 0.0, 3.0),\n",
       " (7, 0.0, 3.0),\n",
       " (9, 0.0, 3.0),\n",
       " (4, 0.0, 0.0),\n",
       " (10, 0.0, 3.0),\n",
       " (8, 0.0, 3.0),\n",
       " (9, 0.0, 0.0),\n",
       " (8, 0.0, 0.0),\n",
       " (4, 0.0, 0.0),\n",
       " (8, 0.0, 0.0),\n",
       " (9, 0.0, 0.0),\n",
       " (15, 0.0, 3.0),\n",
       " (11, 0.0, 3.0),\n",
       " (9, 0.0, 0.0),\n",
       " (7, 0.0, 0.0),\n",
       " (8, 0.0, 3.0),\n",
       " (7, 0.0, 0.0),\n",
       " (7, 0.0, 3.0),\n",
       " (6, 0.0, 0.0),\n",
       " (2, 0.0, 6.0),\n",
       " (3, 0.0, 6.0),\n",
       " (2, 0.0, 6.0),\n",
       " (1, 0.0, 3.0),\n",
       " (6, 0.0, 8.0),\n",
       " (8, 0.0, 6.0),\n",
       " (7, 0.0, 9.0),\n",
       " (5, 0.0, 6.0),\n",
       " (8, 0.0, 8.0),\n",
       " (4, 0.0, 8.0),\n",
       " (7, 0.0, 10.0),\n",
       " (7, 0.0, 10.0),\n",
       " (11, 0.0, 7.0),\n",
       " (13, 0.0, 7.0),\n",
       " (12, 0.0, 7.0),\n",
       " (7, 0.0, 9.0),\n",
       " (12, 0.0, 7.0),\n",
       " (13, 0.0, 9.0),\n",
       " (16, 0.0, 9.0),\n",
       " (13, 0.0, 8.0),\n",
       " (10, 0.0, 11.0),\n",
       " (13, 0.0, 8.0),\n",
       " (5, 0.0, 8.0),\n",
       " (6, 0.0, 9.0),\n",
       " (6, 0.0, 10.0),\n",
       " (2, 0.0, 11.0),\n",
       " (4, 0.0, 11.0),\n",
       " (1, 0.0, 11.0),\n",
       " (7, 0.0, 11.0),\n",
       " (4, 0.0, 10.0),\n",
       " (10, 0.0, 8.0),\n",
       " (7, 0.0, 7.0),\n",
       " (5, 0.0, 13.0),\n",
       " (8, 0.0, 13.0),\n",
       " (8, 0.0, 13.0),\n",
       " (6, 0.0, 16.0),\n",
       " (9, 0.0, 11.0),\n",
       " (8, 0.0, 15.0),\n",
       " (6, 0.0, 14.0),\n",
       " (6, 0.0, 16.0),\n",
       " (6, 0.0, 14.0),\n",
       " (4, 0.0, 16.0),\n",
       " (2, 0.0, 14.0),\n",
       " (1, 0.0, 16.0),\n",
       " (1, 0.0, 13.0),\n",
       " (1, 0.0, 15.0),\n",
       " (1, 0.02, 17.0),\n",
       " (1, 0.0, 16.0),\n",
       " (6, 0.01, 15.0),\n",
       " (35, 0.02, 15.0),\n",
       " (6, 0.02, 24.0),\n",
       " (21, 0.03, 23.0),\n",
       " (6, 0.07, 26.0),\n",
       " (8, 0.04, 29.0),\n",
       " (8, 0.02, 21.0),\n",
       " (1, 0.01, 25.0),\n",
       " (1, 0.0, 15.0),\n",
       " (2, 0.03, 13.0),\n",
       " (2, 0.01, 11.0),\n",
       " (6, 0.01, 15.0),\n",
       " (9, 0.02, 8.0),\n",
       " (4, 0.0, 7.0),\n",
       " (4, 0.0, 7.0),\n",
       " (5, 0.0, 6.0),\n",
       " (6, 0.01, 3.0),\n",
       " (4, 0.0, 5.0),\n",
       " (5, 0.0, 5.0),\n",
       " (5, 0.0, 3.0),\n",
       " (3, 0.0, 7.0),\n",
       " (5, 0.0, 5.0),\n",
       " (5, 0.0, 7.0),\n",
       " (5, 0.0, 9.0),\n",
       " (1, 0.0, 8.0),\n",
       " (3, 0.0, 6.0),\n",
       " (3, 0.0, 8.0),\n",
       " (3, 0.0, 7.0),\n",
       " (3, 0.0, 8.0),\n",
       " (4, 0.0, 3.0),\n",
       " (3, 0.0, 5.0),\n",
       " (1, 0.0, 3.0),\n",
       " (5, 0.0, 6.0),\n",
       " (4, 0.0, 5.0),\n",
       " (5, 0.0, 3.0),\n",
       " (3, 0.0, 5.0),\n",
       " (4, 0.0, 5.0),\n",
       " (10, 0.0, 3.0),\n",
       " (7, 0.0, 9.0),\n",
       " (1, 0.0, 7.0),\n",
       " (5, 0.0, 7.0),\n",
       " (6, 0.0, 6.0),\n",
       " (2, 0.0, 3.0),\n",
       " (4, 0.0, 3.0),\n",
       " (3, 0.0, 3.0),\n",
       " (2, 0.0, 7.0),\n",
       " (3, 0.0, 13.0),\n",
       " (7, 0.0, 7.0),\n",
       " (5, 0.0, 3.0),\n",
       " (9, 0.0, 6.0),\n",
       " (9, 0.0, 6.0),\n",
       " (9, 0.0, 11.0),\n",
       " (4, 0.0, 8.0),\n",
       " (7, 0.0, 8.0),\n",
       " (5, 0.0, 5.0),\n",
       " (4, 0.0, 5.0),\n",
       " (10, 0.0, 9.0),\n",
       " (7, 0.0, 3.0),\n",
       " (6, 0.0, 5.0),\n",
       " (2, 0.0, 8.0),\n",
       " (7, 0.0, 5.0),\n",
       " (3, 0.0, 0.0),\n",
       " (6, 0.0, 5.0),\n",
       " (2, 0.0, 7.0),\n",
       " (1, 0.0, 3.0),\n",
       " (1, 0.0, 3.0),\n",
       " (1, 0.0, 5.0),\n",
       " (2, 0.0, 6.0),\n",
       " (6, 0.0, 5.0),\n",
       " (7, 0.0, 9.0),\n",
       " (6, 0.0, 7.0),\n",
       " (4, 0.0, 7.0),\n",
       " (2, 0.0, 6.0),\n",
       " (11, 0.0, 6.0),\n",
       " (5, 0.0, 5.0),\n",
       " (7, 0.0, 11.0),\n",
       " (3, 0.0, 8.0),\n",
       " (1, 0.0, 9.0),\n",
       " (6, 0.0, 7.0),\n",
       " (10, 0.0, 9.0),\n",
       " (6, 0.0, 7.0),\n",
       " (8, 0.0, 8.0),\n",
       " (4, 0.0, 8.0),\n",
       " (9, 0.0, 7.0),\n",
       " (6, 0.0, 7.0),\n",
       " (11, 0.0, 7.0),\n",
       " (2, 0.0, 7.0),\n",
       " (1, 0.0, 8.0),\n",
       " (2, 0.0, 8.0),\n",
       " (2, 0.0, 7.0),\n",
       " (3, 0.0, 6.0),\n",
       " (3, 0.0, 10.0),\n",
       " (4, 0.0, 13.0),\n",
       " (7, 0.0, 6.0),\n",
       " (10, 0.0, 13.0),\n",
       " (5, 0.0, 13.0),\n",
       " (4, 0.0, 8.0),\n",
       " (9, 0.0, 8.0),\n",
       " (6, 0.0, 7.0),\n",
       " (3, 0.0, 10.0),\n",
       " (10, 0.0, 9.0),\n",
       " (8, 0.0, 9.0),\n",
       " (9, 0.0, 13.0),\n",
       " (11, 0.0, 10.0),\n",
       " (11, 0.0, 9.0),\n",
       " (11, 0.0, 0.0),\n",
       " (18, 0.0, 7.0),\n",
       " (12, 0.0, 9.0),\n",
       " (17, 0.0, 7.0),\n",
       " (9, 0.0, 7.0),\n",
       " (3, 0.0, 7.0),\n",
       " (3, 0.0, 8.0),\n",
       " (4, 0.0, 6.0),\n",
       " (3, 0.0, 3.0),\n",
       " (6, 0.0, 7.0),\n",
       " (3, 0.0, 9.0),\n",
       " (7, 0.0, 6.0),\n",
       " (10, 0.0, 8.0),\n",
       " (9, 0.0, 8.0),\n",
       " (10, 0.0, 7.0),\n",
       " (4, 0.0, 7.0),\n",
       " (8, 0.0, 5.0),\n",
       " (10, 0.0, 5.0),\n",
       " (8, 0.0, 7.0),\n",
       " (7, 0.0, 7.0),\n",
       " (6, 0.0, 6.0),\n",
       " (3, 0.0, 5.0),\n",
       " (5, 0.0, 0.0),\n",
       " (3, 0.0, 5.0),\n",
       " (1, 0.0, 3.0),\n",
       " (2, 0.0, 6.0),\n",
       " (3, 0.0, 8.0),\n",
       " (9, 0.0, 6.0),\n",
       " (5, 0.0, 7.0),\n",
       " (14, 0.0, 3.0),\n",
       " (9, 0.0, 3.0),\n",
       " (6, 0.0, 3.0),\n",
       " (6, 0.0, 5.0),\n",
       " (5, 0.0, 3.0),\n",
       " (5, 0.0, 8.0),\n",
       " (21, 0.0, 5.0),\n",
       " (16, 0.0, 5.0),\n",
       " (9, 0.0, 0.0),\n",
       " (13, 0.0, 3.0),\n",
       " (11, 0.0, 7.0),\n",
       " (5, 0.0, 6.0),\n",
       " (3, 0.0, 9.0),\n",
       " (6, 0.0, 6.0),\n",
       " (3, 0.0, 5.0),\n",
       " (3, 0.0, 8.0),\n",
       " (1, 0.0, 10.0),\n",
       " (1, 0.0, 6.0),\n",
       " (5, 0.0, 5.0),\n",
       " (1, 0.0, 7.0),\n",
       " (9, 0.0, 7.0),\n",
       " (9, 0.0, 8.0),\n",
       " (8, 0.0, 3.0),\n",
       " (6, 0.0, 6.0),\n",
       " (5, 0.0, 7.0),\n",
       " (10, 0.0, 5.0),\n",
       " (12, 0.0, 0.0),\n",
       " (9, 0.0, 6.0),\n",
       " (10, 0.0, 6.0),\n",
       " (8, 0.0, 5.0),\n",
       " (10, 0.0, 5.0),\n",
       " (8, 0.0, 3.0),\n",
       " (16, 0.0, 3.0),\n",
       " (7, 0.0, 7.0),\n",
       " (9, 0.0, 7.0),\n",
       " (8, 0.0, 7.0),\n",
       " (8, 0.0, 3.0)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_6).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1d33ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_6, \"hurricane_rides_and_weather_by_hour.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Create an appropriate visualization for the first query/question in part 3\n",
    "* [ ] Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
    "* [ ] Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport.\n",
    "* [ ] Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.\n",
    "* [ ] Create a scatter plot that compares tip amount versus distance.\n",
    "* [ ] Create another scatter plot that compares tip amount versus precipitation amount.\n",
    "\n",
    "_Be sure these cells are executed so that the visualizations are rendered when the notebook is submitted._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each visualization._\n",
    "\n",
    "_The example below makes use of the `matplotlib` library. There are other libraries, including `pandas` built-in plotting library, kepler for geospatial data representation, `seaborn`, and others._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_n(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_n():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
